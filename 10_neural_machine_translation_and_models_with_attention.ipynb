{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation and Models with Attention\n",
    "Neural Machine Translation is the approach of modeling the entire machine translation process via one big artificial neural network.\n",
    "\n",
    "## Background\n",
    "### Encoder\n",
    "As previously discussed, the architecture is made up of encoder and decoder (two LSTM models.) It reads a source sentence one symbol at a time. The last hidden state summarizes the entire source sentence. This hidden state will be fed into a decoder and result in a sentence of a different language.\n",
    "\n",
    "### Decoder\n",
    "The decoder is a bit different, each timestep is also fed with the last hidden state from the encoder. The last hidden state from encoder is known as a condition. It gives the decoder an awareness of the source text at every timestep which is very useful for translation.\n",
    "\n",
    "$$\n",
    "h_{decoder, t} = f\\left( h_{decoder, t-1}, x_{t}, h_{encoder, f} \\right)\n",
    "$$\n",
    "\n",
    "### Progress of MT\n",
    "![mt_progress](./assets/mt_progress.png)\n",
    "\n",
    "Neural MT was introduced in 2014. People started applying it in 2015. We can clearly see a big improvement from 2015 to 2016 where as other old synatic machine translation remained stagnant over the years.\n",
    "\n",
    "### Four (+) of MT\n",
    "#### End to End Training\n",
    "All parameters are simultaneously optimized to minimize a loss function on the network's output.\n",
    "\n",
    "#### Distributed representations share strength\n",
    "Better exploitation of word and phrase similarities.\n",
    "\n",
    "#### Better exploitation of context\n",
    "NMT can use a much bigger context, both source and partiail target text, to translate more accurately.\n",
    "\n",
    "#### More fluent text generation\n",
    "Deep learning text generation is much higher quality.\n",
    "\n",
    "### Google Translate\n",
    "Here's a sample Chinese text\n",
    "> 1519年600名西班牙人在墨西哥登陸，去征服幾百萬人口的阿茲特克帝國，初次交鋒他們損兵三分之二。\n",
    "\n",
    "A human translation would be\n",
    "> In 1519, 600 Spaniards landed in Mexico to conquer the Aztec Empire with a population of a few million. They lost two thirds of their soldiers in the first clash.\n",
    "\n",
    "In 2009, before the invention of NMT, here's what Google translate returned.\n",
    "> 1519 600 Spaniards landed in Mexico, millions of people to conquer the Aztec empire, the first two-thirds of soliders against their loss.\n",
    "\n",
    "In 2011,\n",
    "> 1519 600 Spaniards landed in Mexico, millions of people to conquer the Aztec empire, the initial loss of soldiers, two thirds of their encounters.\n",
    "\n",
    "In 2013,\n",
    "> 1519 600 Spaniards landed in MExico to conquer the Aztec empire, hundreds of millions of people, the initial confrontation loss of soldiers two-thirds.\n",
    "\n",
    "In 2014/2015/2016,\n",
    "> 1519 600 Spaniards landed in Mexico, millions of people to conquer the Aztec empire, the first two-thirds of the loss of soldiers they clash.\n",
    "\n",
    "Here's the big improvement in 2017,\n",
    "> In 1519, 600 Spaniards landed in Mexico, to conquer the millions of people of the Aztec empire, the first confrontation they killed two-thirds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
