{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "Woo, it's tensorflow again. Let's build some graphs!\n",
    "\n",
    "## Programming Model\n",
    "Tensorflow expresses a numeric computation as a graph. Each node is an operation which has any number of inputs and outputs. Each edge is a tensor which flows between nodes. Suppose we have a simple network expressed by the following operation(s).\n",
    "\n",
    "$$\n",
    "h = \\text{ReLU}(Wx + b)\n",
    "$$\n",
    "\n",
    "We can interpret it as three sequential operations.\n",
    "![tf-graph](./assets/07_tf_graph.png)\n",
    "\n",
    "## Node Types\n",
    "New nodes are automatically built into the underlying graph. We can inspect what are the nodes inside our graph using `get_operations` on our default graph. As we can see there are multiple types of node.\n",
    "```\n",
    "tf.get_default_graph().get_operations()\n",
    "```\n",
    "\n",
    "### Variables\n",
    "Variables are stateful nodes which output their current value. State is retained across multiple executions of a graph. We can think of variables as the parameters we wish to tune. The training will be occurred on variables instead of placeholders.\n",
    "```python\n",
    "b = tf.Variable(tf.zeros((100,)))\n",
    "W = tf.Variable(tf.random_uniform((784, 100), -1, 1))\n",
    "```\n",
    "\n",
    "### Placeholder\n",
    "Placeholders are nodes whose value is fed in at execution time.\n",
    "```python\n",
    "x = tf.placeholder(tf.float32, (100, 784))\n",
    "```\n",
    "\n",
    "### Mathematical operation\n",
    "For example, we have `MatMul`, `Add`, `ReLU` and the list goes on.\n",
    "```python\n",
    "h = tf.nn.relu(tf.matmul(x, W), + b)\n",
    "```\n",
    "\n",
    "## Session\n",
    "Once a graph is defined, we can deploy it with a session, which is a binding to a particular execution context. The `run` method has the followng signature.\n",
    "```\n",
    "sess.run(fetches, feeds)\n",
    "```\n",
    "\n",
    "### Arguments\n",
    "There are two arguments we need to supply to a session.\n",
    "* Fetches - List of graph nodes which will return outputs of these nodes\n",
    "* Feeds - Dictionary mapping from graph nodes to concrete values which will specify the value of placeholder.\n",
    "\n",
    "```python\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "sess.run(h, {x: np.random.random(100, 784)})\n",
    "```\n",
    "\n",
    "### Losses\n",
    "Since labels are not parameters we are going to tune, we will use placeholder for them. In fact, loss is just a mathematical operation node.\n",
    "```python\n",
    "prediction = tf.nn.softmax(...) # Output of a neural network\n",
    "label = tf.placeholder(tf.float32, [100, 10])\n",
    "cross_entropy = -tf.reduce_sum(label * tf.log(prediction), axis=1)\n",
    "```\n",
    "\n",
    "### Optimizer\n",
    "It's time to compute gradients! We need to first define an optimizer object. This should be a familiar concept to me, I have written many different types of optimizer in CS231n. \n",
    "```python\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "```\n",
    "\n",
    "Each graph node has attached gradient operation. The gradient operation computes local gradient and combines it with upstream gradient with respect to loss. In order to use the gradient to update our parameters, we simply run the training step in a session.\n",
    "```python\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(1000):\n",
    "    batch_x, batch_y = data.next_batch()\n",
    "    sess.run(train_step, feed_dict={x: batch_x, label: batch_y})\n",
    "```\n",
    "\n",
    "### Shared Variables\n",
    "What if you are running multiple sessions on a cluster of computers but you are still training one model, i.e. the same set of variables is being used across multiple machines/sessions? We can use `variable_scope`!\n",
    "```python\n",
    "with tf.variable_scope('foo'):\n",
    "    v = tf._get_variable('v', shape=[1]) # v.name == \"foo/v:0\"\n",
    "   \n",
    "with tf.variable_scope('foo', reuse=True):\n",
    "    v1 = tf.get_variable('v') # shared variable found!\n",
    "   \n",
    "with tf.variable_scope('foo', reuse=False):\n",
    "    v1 = tf.get_variable('v') # CRASH foo/v:0 already exists\n",
    "```\n",
    "\n",
    "`variable_scope()` provides simple name-spacingto avoid clashes. `get_variable()` creates/accesses variables from within a variable scope. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    x_batch = np.linspace(-1, 1, 101)\n",
    "    y_batch = 2 * x_batch + np.random.randn(*x_batch.shape) * 0.3 # Give it some noise\n",
    "    return x_batch, y_batch\n",
    "\n",
    "\n",
    "def linear_regression():\n",
    "    x = tf.placeholder(tf.float32, shape=(None,), name='x') # Shape none makes it flexible\n",
    "    y = tf.placeholder(tf.float32, shape=(None,), name='y')\n",
    "    \n",
    "    with tf.variable_scope('linreg') as scope:\n",
    "        w = tf.Variable(np.random.normal(), name='W')\n",
    "        y_pred = tf.multiply(x, w)\n",
    "        loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "    \n",
    "    return x, y, y_pred, loss\n",
    "\n",
    "\n",
    "def train():\n",
    "    x_batch, y_batch = generate_dataset()\n",
    "    x, y, y_pred, loss = linear_regression()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        feed_dict = {x: x_batch, y: y_batch} # x is a tensor placeholder and is hashable\n",
    "        for i in range(30):\n",
    "            loss_val, _ = sess.run([loss, optimizer], feed_dict)\n",
    "        \n",
    "        y_pred_batch = sess.run(y_pred, {x: x_batch})\n",
    "    \n",
    "    plt.plot(x_batch, y_batch, x_batch, y_pred_batch)\n",
    "    plt.show()\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Word2Vec Skip-Gram\n",
    "\n",
    "Each unprocessed input is a sentence. For example, \"Ever since I use TypeScript, I can't go back to JavaScript\".\n",
    "For a window size of 1, the processed dataset should look like\n",
    "```python\n",
    "(['Ever', 'I'], 'since'), (['since', 'use'], 'I'), (['I', 'TypeScript'], 'use'), ...\n",
    "```\n",
    "\n",
    "Skip-Gram model tries to predict each context word from its target word. The final data set will look like.\n",
    "```python\n",
    "('since', 'Ever'), ('since', 'I'), ('I', 'since'), ('I', 'use'), ...\n",
    "```\n",
    "\n",
    "### Load data\n",
    "We need to load data and massage them into the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import collections\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tempfile import gettempdir\n",
    "from six.moves import urllib\n",
    "\n",
    "\n",
    "def download(filename, expected_bytes):\n",
    "    \"\"\"Download a zip folder to temp folder on Linux\"\"\"\n",
    "    local_filename = os.path.join(gettempdir(), filename)\n",
    "    if not os.path.exists(local_filename):\n",
    "        local_filename, _ = urllib.request.urlretrieve(url+filename, local_filename)\n",
    "\n",
    "    statinfo = os.stat(local_filename)\n",
    "    if statinfo.st_size != expected_bytes:\n",
    "        raise Exception('wrong size ' + statinfo.st_size + ' failed to verify ' + filename)\n",
    "    \n",
    "    return local_filename\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"Extract the file file enclosed in a zip file as a list of strings\"\"\"\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def build_dataset(words, vocab_size):\n",
    "    \"\"\"Builds a dataset, which is a list of integers. Each integer maps to a word.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocab_size - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0: # Equivalent to dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    \n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "\n",
    "def generate_batch(raw_data, batch_size, num_skips, skip_window):\n",
    "    \"\"\"Generate a training batch for the skip-gram model\"\"\"\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1 # [skip_window target skip_window]\n",
    "    buffer = collections.deque(maxlen=span) \n",
    "\n",
    "    if data_index + span > len(raw_data):\n",
    "        data_index = 0\n",
    "\n",
    "    buffer.extend(raw_data[data_index:data_index+span])\n",
    "    data_index += span\n",
    "    for i in range(batch_size//num_skips):\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "        words_to_use = random.sample(context_words, num_skips)\n",
    "        for j, context_word in enumerate(words_to_use):\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j] = buffer[context_word]\n",
    "\n",
    "        if data_index == len(data):\n",
    "            buffer.extend(raw_data[0:span])\n",
    "            data_index = span\n",
    "        else:\n",
    "            buffer.append(raw_data[data_index])\n",
    "            data_index += 1\n",
    "\n",
    "    data_index = (data_index + len(raw_data) - span) % len(raw_data)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded /tmp/text8.zip\n",
      "word count 17005207\n",
      "most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n",
      "sample data\n",
      "[5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156]\n",
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "vocabulary_size = 50000\n",
    "data_index = 0\n",
    "\n",
    "filename = download('text8.zip', 31344016)\n",
    "word_list = read_data(filename)\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(word_list, vocabulary_size)\n",
    "\n",
    "print 'loaded %s' % filename\n",
    "print 'word count %d' % len(word_list)\n",
    "print 'most common words (+UNK)', count[:5]\n",
    "print 'sample data'\n",
    "print data[:10]\n",
    "print [reverse_dictionary[i] for i in data[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To `numpy.Array`\n",
    "Now we need to turn these data into numpy array so we can feed them into our tensorflow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(raw_data, batch_size, num_skips, skip_window):\n",
    "    \"\"\"Generate a training batch for the skip-gram model\"\"\"\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1 # [skip_window target skip_window]\n",
    "    buffer = collections.deque(maxlen=span) \n",
    "\n",
    "    if data_index + span > len(raw_data):\n",
    "        data_index = 0\n",
    "\n",
    "    buffer.extend(raw_data[data_index:data_index+span])\n",
    "    data_index += span\n",
    "    for i in range(batch_size//num_skips):\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "        words_to_use = random.sample(context_words, num_skips)\n",
    "        for j, context_word in enumerate(words_to_use):\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j] = buffer[context_word]\n",
    "\n",
    "        if data_index == len(data):\n",
    "            buffer.extend(raw_data[0:span])\n",
    "            data_index = span\n",
    "        else:\n",
    "            buffer.append(raw_data[data_index])\n",
    "            data_index += 1\n",
    "\n",
    "    data_index = (data_index + len(raw_data) - span) % len(raw_data)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example of how a batch input is mapped to a batch label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 of -> 195 term\n",
      "2 of -> 3137 abuse\n",
      "3137 abuse -> 2 of\n",
      "3137 abuse -> 46 first\n",
      "46 first -> 59 used\n",
      "46 first -> 3137 abuse\n",
      "59 used -> 46 first\n",
      "59 used -> 156 against\n"
     ]
    }
   ],
   "source": [
    "batch, labels = generate_batch(data, batch_size=8, num_skips=2, skip_window=1)\n",
    "for i in range(8):\n",
    "    print batch[i], reverse_dictionary[batch[i]], '->', labels[i, 0], reverse_dictionary[labels[i, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128 # Dimension of embedding vector\n",
    "skip_window = 1\n",
    "num_skips = 2\n",
    "num_sampled = 64\n",
    "\n",
    "# Construct validation set\n",
    "valid_size = 16\n",
    "valid_examples = np.random.choice(100, valid_size, replace=False)\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('inputs'):\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "        train_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\n",
    "        valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        with tf.name_scope('embeddings'):\n",
    "            embeddings = tf.Variable(tf.random_uniform((vocabulary_size, embedding_size), -1, 1))\n",
    "            embed_lookup = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "        with tf.name_scope('weights'):\n",
    "            nce_weights = tf.Variable(tf.truncated_normal((vocabulary_size, embedding_size), stddev=1 / np.sqrt(embedding_size)))\n",
    "\n",
    "        with tf.name_scope('biases'):\n",
    "            nce_biases = tf.Variable(tf.zeros((vocabulary_size)))\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(\n",
    "                tf.nn.nce_loss(\n",
    "                    weights=nce_weights,\n",
    "                    biases=nce_biases,\n",
    "                    labels=train_labels,\n",
    "                    inputs=embed_lookup,\n",
    "                    num_sampled=num_sampled,\n",
    "                    num_classes=vocabulary_size))\n",
    "        \n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "    \n",
    "    # Compute cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embed_lookup = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embed_lookup, normalized_embeddings, transpose_b=True)\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it\n",
    "Once the graph is built, we can start a new session to execute the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph variables initialized\n",
      "average loss at step  0 :  269.2176513671875\n",
      "Nearest to zero: sally,\n",
      "Nearest to zero: peptidoglycan,\n",
      "Nearest to zero: generalized,\n",
      "Nearest to zero: compelled,\n",
      "Nearest to zero: dorn,\n",
      "Nearest to zero: secondo,\n",
      "Nearest to zero: rem,\n",
      "Nearest to zero: bromine,\n",
      "Nearest to into: iconoclastic,\n",
      "Nearest to into: formats,\n",
      "Nearest to into: nanda,\n",
      "Nearest to into: posterity,\n",
      "Nearest to into: dethroned,\n",
      "Nearest to into: irian,\n",
      "Nearest to into: coo,\n",
      "Nearest to into: cleaned,\n",
      "Nearest to called: aerobatics,\n",
      "Nearest to called: dramatization,\n",
      "Nearest to called: protecting,\n",
      "Nearest to called: boats,\n",
      "Nearest to called: varphi,\n",
      "Nearest to called: births,\n",
      "Nearest to called: imposed,\n",
      "Nearest to called: atum,\n",
      "Nearest to than: believes,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: raven,\n",
      "Nearest to than: disrupted,\n",
      "Nearest to than: overlaid,\n",
      "Nearest to than: downgraded,\n",
      "Nearest to than: rains,\n",
      "Nearest to than: nikita,\n",
      "Nearest to use: industrialization,\n",
      "Nearest to use: birger,\n",
      "Nearest to use: catalogued,\n",
      "Nearest to use: expansionism,\n",
      "Nearest to use: writer,\n",
      "Nearest to use: gandalf,\n",
      "Nearest to use: institutional,\n",
      "Nearest to use: story,\n",
      "Nearest to no: cypriots,\n",
      "Nearest to no: ethnocentrism,\n",
      "Nearest to no: claimants,\n",
      "Nearest to no: croatians,\n",
      "Nearest to no: cases,\n",
      "Nearest to no: demoralized,\n",
      "Nearest to no: panthers,\n",
      "Nearest to no: grau,\n",
      "Nearest to from: hanns,\n",
      "Nearest to from: scans,\n",
      "Nearest to from: learning,\n",
      "Nearest to from: klm,\n",
      "Nearest to from: tory,\n",
      "Nearest to from: epicureanism,\n",
      "Nearest to from: developer,\n",
      "Nearest to from: marshal,\n",
      "Nearest to this: passos,\n",
      "Nearest to this: babbage,\n",
      "Nearest to this: antiparticles,\n",
      "Nearest to this: patriots,\n",
      "Nearest to this: affirming,\n",
      "Nearest to this: stereotyped,\n",
      "Nearest to this: inklings,\n",
      "Nearest to this: korea,\n",
      "Nearest to b: bold,\n",
      "Nearest to b: grammatical,\n",
      "Nearest to b: xinhua,\n",
      "Nearest to b: somerset,\n",
      "Nearest to b: paving,\n",
      "Nearest to b: haus,\n",
      "Nearest to b: dorsal,\n",
      "Nearest to b: poignant,\n",
      "Nearest to by: cristobal,\n",
      "Nearest to by: telepathy,\n",
      "Nearest to by: adrien,\n",
      "Nearest to by: australia,\n",
      "Nearest to by: obvious,\n",
      "Nearest to by: vhdl,\n",
      "Nearest to by: swap,\n",
      "Nearest to by: replenishment,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: magnetite,\n",
      "Nearest to some: organizing,\n",
      "Nearest to some: infra,\n",
      "Nearest to some: panel,\n",
      "Nearest to some: outreach,\n",
      "Nearest to some: watershed,\n",
      "Nearest to some: hoop,\n",
      "Nearest to eight: eroding,\n",
      "Nearest to eight: narrower,\n",
      "Nearest to eight: ports,\n",
      "Nearest to eight: notate,\n",
      "Nearest to eight: mantis,\n",
      "Nearest to eight: splitting,\n",
      "Nearest to eight: tewahedo,\n",
      "Nearest to eight: selection,\n",
      "Nearest to their: ductile,\n",
      "Nearest to their: diger,\n",
      "Nearest to their: hayward,\n",
      "Nearest to their: tintin,\n",
      "Nearest to their: misgivings,\n",
      "Nearest to their: goods,\n",
      "Nearest to their: unleashing,\n",
      "Nearest to their: seljuk,\n",
      "Nearest to three: polyn,\n",
      "Nearest to three: estrogen,\n",
      "Nearest to three: reserves,\n",
      "Nearest to three: trieste,\n",
      "Nearest to three: raging,\n",
      "Nearest to three: keitel,\n",
      "Nearest to three: epicycle,\n",
      "Nearest to three: micronations,\n",
      "Nearest to of: zoster,\n",
      "Nearest to of: weapons,\n",
      "Nearest to of: illicit,\n",
      "Nearest to of: milit,\n",
      "Nearest to of: doomed,\n",
      "Nearest to of: embargo,\n",
      "Nearest to of: terminally,\n",
      "Nearest to of: trolleys,\n",
      "Nearest to that: sven,\n",
      "Nearest to that: shatner,\n",
      "Nearest to that: harpers,\n",
      "Nearest to that: unsaturated,\n",
      "Nearest to that: furthermore,\n",
      "Nearest to that: scarred,\n",
      "Nearest to that: azul,\n",
      "Nearest to that: screwball,\n",
      "average loss at step  2000 :  113.32543200683594\n",
      "average loss at step  4000 :  53.01030317401886\n",
      "average loss at step  6000 :  33.42544966459274\n",
      "average loss at step  8000 :  23.474363171219824\n",
      "average loss at step  10000 :  17.793463396310806\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: coke,\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: agave,\n",
      "Nearest to zero: phi,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: gland,\n",
      "Nearest to into: in,\n",
      "Nearest to into: hooker,\n",
      "Nearest to into: and,\n",
      "Nearest to into: lord,\n",
      "Nearest to into: leagues,\n",
      "Nearest to into: parerga,\n",
      "Nearest to into: cat,\n",
      "Nearest to into: antarctica,\n",
      "Nearest to called: births,\n",
      "Nearest to called: boats,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: saw,\n",
      "Nearest to called: powers,\n",
      "Nearest to called: imposed,\n",
      "Nearest to called: gulch,\n",
      "Nearest to called: protecting,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: believes,\n",
      "Nearest to than: telephone,\n",
      "Nearest to than: raven,\n",
      "Nearest to than: much,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: bckgr,\n",
      "Nearest to than: dispelling,\n",
      "Nearest to use: story,\n",
      "Nearest to use: writer,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: gap,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: chose,\n",
      "Nearest to use: junctions,\n",
      "Nearest to use: democracy,\n",
      "Nearest to no: motile,\n",
      "Nearest to no: hakama,\n",
      "Nearest to no: user,\n",
      "Nearest to no: cases,\n",
      "Nearest to no: ernst,\n",
      "Nearest to no: macedonian,\n",
      "Nearest to no: terminated,\n",
      "Nearest to no: drawn,\n",
      "Nearest to from: marriage,\n",
      "Nearest to from: learning,\n",
      "Nearest to from: of,\n",
      "Nearest to from: by,\n",
      "Nearest to from: in,\n",
      "Nearest to from: agave,\n",
      "Nearest to from: isbn,\n",
      "Nearest to from: deny,\n",
      "Nearest to this: the,\n",
      "Nearest to this: patriots,\n",
      "Nearest to this: he,\n",
      "Nearest to this: attend,\n",
      "Nearest to this: affirming,\n",
      "Nearest to this: his,\n",
      "Nearest to this: crazy,\n",
      "Nearest to this: vs,\n",
      "Nearest to b: grammatical,\n",
      "Nearest to b: roman,\n",
      "Nearest to b: bold,\n",
      "Nearest to b: cardinality,\n",
      "Nearest to b: out,\n",
      "Nearest to b: theodore,\n",
      "Nearest to b: plural,\n",
      "Nearest to b: somerset,\n",
      "Nearest to by: in,\n",
      "Nearest to by: and,\n",
      "Nearest to by: to,\n",
      "Nearest to by: coke,\n",
      "Nearest to by: from,\n",
      "Nearest to by: gland,\n",
      "Nearest to by: sb,\n",
      "Nearest to by: acid,\n",
      "Nearest to some: solf,\n",
      "Nearest to some: canadians,\n",
      "Nearest to some: sagan,\n",
      "Nearest to some: coke,\n",
      "Nearest to some: daniel,\n",
      "Nearest to some: watershed,\n",
      "Nearest to some: volkswagen,\n",
      "Nearest to some: exact,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: agave,\n",
      "Nearest to eight: phi,\n",
      "Nearest to eight: coke,\n",
      "Nearest to eight: vs,\n",
      "Nearest to eight: six,\n",
      "Nearest to their: goods,\n",
      "Nearest to their: seljuk,\n",
      "Nearest to their: astrological,\n",
      "Nearest to their: df,\n",
      "Nearest to their: agree,\n",
      "Nearest to their: commands,\n",
      "Nearest to their: fossil,\n",
      "Nearest to their: beer,\n",
      "Nearest to three: five,\n",
      "Nearest to three: nine,\n",
      "Nearest to three: six,\n",
      "Nearest to three: phi,\n",
      "Nearest to three: zero,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: one,\n",
      "Nearest to three: jpg,\n",
      "Nearest to of: and,\n",
      "Nearest to of: in,\n",
      "Nearest to of: for,\n",
      "Nearest to of: tribe,\n",
      "Nearest to of: the,\n",
      "Nearest to of: nine,\n",
      "Nearest to of: gland,\n",
      "Nearest to of: at,\n",
      "Nearest to that: purposes,\n",
      "Nearest to that: bordered,\n",
      "Nearest to that: black,\n",
      "Nearest to that: which,\n",
      "Nearest to that: happen,\n",
      "Nearest to that: niece,\n",
      "Nearest to that: respected,\n",
      "Nearest to that: stars,\n",
      "average loss at step  12000 :  13.511742930531502\n",
      "average loss at step  14000 :  11.7642374420166\n",
      "average loss at step  16000 :  10.095958055138588\n",
      "average loss at step  18000 :  8.464367826461793\n",
      "average loss at step  20000 :  8.033435933113099\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: agouti,\n",
      "Nearest to into: in,\n",
      "Nearest to into: and,\n",
      "Nearest to into: with,\n",
      "Nearest to into: from,\n",
      "Nearest to into: by,\n",
      "Nearest to into: jeremiah,\n",
      "Nearest to into: coo,\n",
      "Nearest to into: as,\n",
      "Nearest to called: hbox,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: powers,\n",
      "Nearest to called: or,\n",
      "Nearest to called: rainfall,\n",
      "Nearest to called: boats,\n",
      "Nearest to called: heritage,\n",
      "Nearest to called: saw,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: much,\n",
      "Nearest to than: raven,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: believes,\n",
      "Nearest to than: telephone,\n",
      "Nearest to than: sod,\n",
      "Nearest to than: adriatic,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: story,\n",
      "Nearest to use: writer,\n",
      "Nearest to use: circ,\n",
      "Nearest to use: incompressible,\n",
      "Nearest to use: castile,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: gap,\n",
      "Nearest to no: hakama,\n",
      "Nearest to no: user,\n",
      "Nearest to no: aluminum,\n",
      "Nearest to no: motile,\n",
      "Nearest to no: terminated,\n",
      "Nearest to no: plutarch,\n",
      "Nearest to no: drawn,\n",
      "Nearest to no: formulated,\n",
      "Nearest to from: by,\n",
      "Nearest to from: in,\n",
      "Nearest to from: of,\n",
      "Nearest to from: nine,\n",
      "Nearest to from: and,\n",
      "Nearest to from: on,\n",
      "Nearest to from: during,\n",
      "Nearest to from: at,\n",
      "Nearest to this: the,\n",
      "Nearest to this: it,\n",
      "Nearest to this: which,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: his,\n",
      "Nearest to this: agouti,\n",
      "Nearest to this: a,\n",
      "Nearest to this: one,\n",
      "Nearest to b: d,\n",
      "Nearest to b: roman,\n",
      "Nearest to b: sketch,\n",
      "Nearest to b: and,\n",
      "Nearest to b: grammatical,\n",
      "Nearest to b: cardinality,\n",
      "Nearest to b: ammonius,\n",
      "Nearest to b: theodore,\n",
      "Nearest to by: in,\n",
      "Nearest to by: and,\n",
      "Nearest to by: was,\n",
      "Nearest to by: from,\n",
      "Nearest to by: with,\n",
      "Nearest to by: as,\n",
      "Nearest to by: is,\n",
      "Nearest to by: agouti,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: canadians,\n",
      "Nearest to some: sagan,\n",
      "Nearest to some: the,\n",
      "Nearest to some: volkswagen,\n",
      "Nearest to some: chechnya,\n",
      "Nearest to some: affiliates,\n",
      "Nearest to some: solf,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: circ,\n",
      "Nearest to their: the,\n",
      "Nearest to their: his,\n",
      "Nearest to their: its,\n",
      "Nearest to their: goods,\n",
      "Nearest to their: seljuk,\n",
      "Nearest to their: astrological,\n",
      "Nearest to their: fossil,\n",
      "Nearest to their: journeyed,\n",
      "Nearest to three: five,\n",
      "Nearest to three: nine,\n",
      "Nearest to three: six,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: zero,\n",
      "Nearest to three: four,\n",
      "Nearest to three: two,\n",
      "Nearest to three: circ,\n",
      "Nearest to of: and,\n",
      "Nearest to of: in,\n",
      "Nearest to of: for,\n",
      "Nearest to of: circ,\n",
      "Nearest to of: nine,\n",
      "Nearest to of: agouti,\n",
      "Nearest to of: gland,\n",
      "Nearest to of: or,\n",
      "Nearest to that: which,\n",
      "Nearest to that: and,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: purposes,\n",
      "Nearest to that: mound,\n",
      "Nearest to that: this,\n",
      "Nearest to that: niece,\n",
      "Nearest to that: happen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss at step  22000 :  7.0178017911911015\n",
      "average loss at step  24000 :  6.923363940238953\n",
      "average loss at step  26000 :  6.825277869462967\n",
      "average loss at step  28000 :  6.412920020341873\n",
      "average loss at step  30000 :  6.001151402592659\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: abet,\n",
      "Nearest to into: from,\n",
      "Nearest to into: with,\n",
      "Nearest to into: in,\n",
      "Nearest to into: by,\n",
      "Nearest to into: to,\n",
      "Nearest to into: jeremiah,\n",
      "Nearest to into: as,\n",
      "Nearest to into: and,\n",
      "Nearest to called: varphi,\n",
      "Nearest to called: or,\n",
      "Nearest to called: aerobatics,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: dramatization,\n",
      "Nearest to called: rainfall,\n",
      "Nearest to called: and,\n",
      "Nearest to called: hbox,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: much,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: raven,\n",
      "Nearest to than: sod,\n",
      "Nearest to than: or,\n",
      "Nearest to than: believes,\n",
      "Nearest to than: telephone,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: writer,\n",
      "Nearest to use: story,\n",
      "Nearest to use: incompressible,\n",
      "Nearest to use: castile,\n",
      "Nearest to use: circ,\n",
      "Nearest to use: expansionism,\n",
      "Nearest to no: there,\n",
      "Nearest to no: aluminum,\n",
      "Nearest to no: terminated,\n",
      "Nearest to no: hakama,\n",
      "Nearest to no: plutarch,\n",
      "Nearest to no: formulated,\n",
      "Nearest to no: drawn,\n",
      "Nearest to no: user,\n",
      "Nearest to from: in,\n",
      "Nearest to from: by,\n",
      "Nearest to from: of,\n",
      "Nearest to from: during,\n",
      "Nearest to from: and,\n",
      "Nearest to from: at,\n",
      "Nearest to from: on,\n",
      "Nearest to from: into,\n",
      "Nearest to this: the,\n",
      "Nearest to this: it,\n",
      "Nearest to this: which,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: agouti,\n",
      "Nearest to this: one,\n",
      "Nearest to this: that,\n",
      "Nearest to this: his,\n",
      "Nearest to b: d,\n",
      "Nearest to b: sketch,\n",
      "Nearest to b: roman,\n",
      "Nearest to b: grammatical,\n",
      "Nearest to b: one,\n",
      "Nearest to b: ammonius,\n",
      "Nearest to b: and,\n",
      "Nearest to b: cardinality,\n",
      "Nearest to by: in,\n",
      "Nearest to by: from,\n",
      "Nearest to by: was,\n",
      "Nearest to by: with,\n",
      "Nearest to by: and,\n",
      "Nearest to by: as,\n",
      "Nearest to by: through,\n",
      "Nearest to by: agouti,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: the,\n",
      "Nearest to some: many,\n",
      "Nearest to some: canadians,\n",
      "Nearest to some: sagan,\n",
      "Nearest to some: volkswagen,\n",
      "Nearest to some: affiliates,\n",
      "Nearest to some: solf,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: circ,\n",
      "Nearest to their: the,\n",
      "Nearest to their: his,\n",
      "Nearest to their: its,\n",
      "Nearest to their: goods,\n",
      "Nearest to their: fossil,\n",
      "Nearest to their: seljuk,\n",
      "Nearest to their: journeyed,\n",
      "Nearest to their: s,\n",
      "Nearest to three: six,\n",
      "Nearest to three: five,\n",
      "Nearest to three: four,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: two,\n",
      "Nearest to three: nine,\n",
      "Nearest to three: seven,\n",
      "Nearest to three: zero,\n",
      "Nearest to of: and,\n",
      "Nearest to of: in,\n",
      "Nearest to of: for,\n",
      "Nearest to of: from,\n",
      "Nearest to of: eight,\n",
      "Nearest to of: circ,\n",
      "Nearest to of: agouti,\n",
      "Nearest to of: nine,\n",
      "Nearest to that: which,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: this,\n",
      "Nearest to that: happen,\n",
      "Nearest to that: purposes,\n",
      "Nearest to that: mound,\n",
      "Nearest to that: it,\n",
      "Nearest to that: niece,\n",
      "average loss at step  32000 :  5.999006610751152\n",
      "average loss at step  34000 :  5.674795457005501\n",
      "average loss at step  36000 :  5.718891700625419\n",
      "average loss at step  38000 :  5.494446519970894\n",
      "average loss at step  40000 :  5.238022464036941\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: circ,\n",
      "Nearest to into: from,\n",
      "Nearest to into: with,\n",
      "Nearest to into: in,\n",
      "Nearest to into: jeremiah,\n",
      "Nearest to into: under,\n",
      "Nearest to into: by,\n",
      "Nearest to into: and,\n",
      "Nearest to into: coo,\n",
      "Nearest to called: and,\n",
      "Nearest to called: varphi,\n",
      "Nearest to called: or,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: rainfall,\n",
      "Nearest to called: while,\n",
      "Nearest to called: aerobatics,\n",
      "Nearest to called: dramatization,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: much,\n",
      "Nearest to than: or,\n",
      "Nearest to than: raven,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: sod,\n",
      "Nearest to than: believes,\n",
      "Nearest to than: adriatic,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: incompressible,\n",
      "Nearest to use: circ,\n",
      "Nearest to use: industrialization,\n",
      "Nearest to use: story,\n",
      "Nearest to use: castile,\n",
      "Nearest to use: consequently,\n",
      "Nearest to no: there,\n",
      "Nearest to no: aluminum,\n",
      "Nearest to no: oxidized,\n",
      "Nearest to no: drawn,\n",
      "Nearest to no: terminated,\n",
      "Nearest to no: formulated,\n",
      "Nearest to no: plutarch,\n",
      "Nearest to no: he,\n",
      "Nearest to from: in,\n",
      "Nearest to from: on,\n",
      "Nearest to from: into,\n",
      "Nearest to from: during,\n",
      "Nearest to from: by,\n",
      "Nearest to from: after,\n",
      "Nearest to from: at,\n",
      "Nearest to from: of,\n",
      "Nearest to this: which,\n",
      "Nearest to this: the,\n",
      "Nearest to this: it,\n",
      "Nearest to this: that,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: a,\n",
      "Nearest to this: one,\n",
      "Nearest to this: agouti,\n",
      "Nearest to b: d,\n",
      "Nearest to b: eight,\n",
      "Nearest to b: sketch,\n",
      "Nearest to b: ammonius,\n",
      "Nearest to b: UNK,\n",
      "Nearest to b: grammatical,\n",
      "Nearest to b: zero,\n",
      "Nearest to b: three,\n",
      "Nearest to by: was,\n",
      "Nearest to by: in,\n",
      "Nearest to by: from,\n",
      "Nearest to by: be,\n",
      "Nearest to by: agouti,\n",
      "Nearest to by: coke,\n",
      "Nearest to by: with,\n",
      "Nearest to by: is,\n",
      "Nearest to some: many,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: the,\n",
      "Nearest to some: these,\n",
      "Nearest to some: sagan,\n",
      "Nearest to some: affiliates,\n",
      "Nearest to some: canadians,\n",
      "Nearest to some: volkswagen,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: one,\n",
      "Nearest to their: its,\n",
      "Nearest to their: his,\n",
      "Nearest to their: the,\n",
      "Nearest to their: vdc,\n",
      "Nearest to their: fossil,\n",
      "Nearest to their: goods,\n",
      "Nearest to their: seljuk,\n",
      "Nearest to their: astrological,\n",
      "Nearest to three: four,\n",
      "Nearest to three: five,\n",
      "Nearest to three: six,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: seven,\n",
      "Nearest to three: two,\n",
      "Nearest to three: zero,\n",
      "Nearest to three: nine,\n",
      "Nearest to of: in,\n",
      "Nearest to of: albury,\n",
      "Nearest to of: and,\n",
      "Nearest to of: vdc,\n",
      "Nearest to of: agouti,\n",
      "Nearest to of: for,\n",
      "Nearest to of: from,\n",
      "Nearest to of: nine,\n",
      "Nearest to that: which,\n",
      "Nearest to that: this,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: it,\n",
      "Nearest to that: generally,\n",
      "Nearest to that: mound,\n",
      "Nearest to that: but,\n",
      "Nearest to that: purposes,\n",
      "average loss at step  42000 :  5.3480899097919465\n",
      "average loss at step  44000 :  5.226381867289543\n",
      "average loss at step  46000 :  5.244071110725403\n",
      "average loss at step  48000 :  5.20865438592434\n",
      "average loss at step  50000 :  4.980210625171662\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: agouti,\n",
      "Nearest to into: from,\n",
      "Nearest to into: with,\n",
      "Nearest to into: in,\n",
      "Nearest to into: jeremiah,\n",
      "Nearest to into: under,\n",
      "Nearest to into: on,\n",
      "Nearest to into: as,\n",
      "Nearest to into: to,\n",
      "Nearest to called: UNK,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: while,\n",
      "Nearest to called: varphi,\n",
      "Nearest to called: and,\n",
      "Nearest to called: or,\n",
      "Nearest to called: rainfall,\n",
      "Nearest to called: aerobatics,\n",
      "Nearest to than: or,\n",
      "Nearest to than: much,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: episkopos,\n",
      "Nearest to than: sod,\n",
      "Nearest to than: believes,\n",
      "Nearest to than: and,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: incompressible,\n",
      "Nearest to use: story,\n",
      "Nearest to use: industrialization,\n",
      "Nearest to use: circ,\n",
      "Nearest to use: marek,\n",
      "Nearest to use: castile,\n",
      "Nearest to no: there,\n",
      "Nearest to no: mcduck,\n",
      "Nearest to no: oxidized,\n",
      "Nearest to no: plutarch,\n",
      "Nearest to no: drawn,\n",
      "Nearest to no: airshow,\n",
      "Nearest to no: aluminum,\n",
      "Nearest to no: formulated,\n",
      "Nearest to from: in,\n",
      "Nearest to from: into,\n",
      "Nearest to from: by,\n",
      "Nearest to from: during,\n",
      "Nearest to from: and,\n",
      "Nearest to from: after,\n",
      "Nearest to from: on,\n",
      "Nearest to from: of,\n",
      "Nearest to this: which,\n",
      "Nearest to this: it,\n",
      "Nearest to this: the,\n",
      "Nearest to this: that,\n",
      "Nearest to this: cem,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: another,\n",
      "Nearest to this: agouti,\n",
      "Nearest to b: d,\n",
      "Nearest to b: ammonius,\n",
      "Nearest to b: eight,\n",
      "Nearest to b: sketch,\n",
      "Nearest to b: canons,\n",
      "Nearest to b: three,\n",
      "Nearest to b: recitative,\n",
      "Nearest to b: six,\n",
      "Nearest to by: was,\n",
      "Nearest to by: from,\n",
      "Nearest to by: in,\n",
      "Nearest to by: for,\n",
      "Nearest to by: through,\n",
      "Nearest to by: be,\n",
      "Nearest to by: seven,\n",
      "Nearest to by: coke,\n",
      "Nearest to some: many,\n",
      "Nearest to some: these,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: the,\n",
      "Nearest to some: sagan,\n",
      "Nearest to some: different,\n",
      "Nearest to some: affiliates,\n",
      "Nearest to some: factbook,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: one,\n",
      "Nearest to their: his,\n",
      "Nearest to their: its,\n",
      "Nearest to their: the,\n",
      "Nearest to their: her,\n",
      "Nearest to their: vdc,\n",
      "Nearest to their: fossil,\n",
      "Nearest to their: them,\n",
      "Nearest to their: reaction,\n",
      "Nearest to three: four,\n",
      "Nearest to three: five,\n",
      "Nearest to three: six,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: two,\n",
      "Nearest to three: seven,\n",
      "Nearest to three: one,\n",
      "Nearest to three: circ,\n",
      "Nearest to of: for,\n",
      "Nearest to of: in,\n",
      "Nearest to of: albury,\n",
      "Nearest to of: vdc,\n",
      "Nearest to of: agouti,\n",
      "Nearest to of: from,\n",
      "Nearest to of: and,\n",
      "Nearest to of: eight,\n",
      "Nearest to that: which,\n",
      "Nearest to that: this,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: mound,\n",
      "Nearest to that: generally,\n",
      "Nearest to that: recitative,\n",
      "Nearest to that: where,\n",
      "Nearest to that: it,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss at step  52000 :  5.0292595138549805\n",
      "average loss at step  54000 :  5.186040455818176\n",
      "average loss at step  56000 :  5.065717501759529\n",
      "average loss at step  58000 :  5.057817447185516\n",
      "average loss at step  60000 :  4.942558523774147\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: ursus,\n",
      "Nearest to into: from,\n",
      "Nearest to into: with,\n",
      "Nearest to into: under,\n",
      "Nearest to into: on,\n",
      "Nearest to into: jeremiah,\n",
      "Nearest to into: in,\n",
      "Nearest to into: against,\n",
      "Nearest to into: by,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: and,\n",
      "Nearest to called: varphi,\n",
      "Nearest to called: while,\n",
      "Nearest to called: pulau,\n",
      "Nearest to called: ursus,\n",
      "Nearest to called: selig,\n",
      "Nearest to called: bennett,\n",
      "Nearest to than: or,\n",
      "Nearest to than: much,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: episkopos,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: and,\n",
      "Nearest to than: sod,\n",
      "Nearest to than: raven,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: marek,\n",
      "Nearest to use: pulau,\n",
      "Nearest to use: circ,\n",
      "Nearest to use: industrialization,\n",
      "Nearest to use: microsite,\n",
      "Nearest to use: incompressible,\n",
      "Nearest to no: there,\n",
      "Nearest to no: mcduck,\n",
      "Nearest to no: oxidized,\n",
      "Nearest to no: a,\n",
      "Nearest to no: airshow,\n",
      "Nearest to no: stalemate,\n",
      "Nearest to no: drawn,\n",
      "Nearest to no: eight,\n",
      "Nearest to from: in,\n",
      "Nearest to from: after,\n",
      "Nearest to from: into,\n",
      "Nearest to from: during,\n",
      "Nearest to from: by,\n",
      "Nearest to from: at,\n",
      "Nearest to from: on,\n",
      "Nearest to from: agouti,\n",
      "Nearest to this: which,\n",
      "Nearest to this: it,\n",
      "Nearest to this: the,\n",
      "Nearest to this: that,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: cem,\n",
      "Nearest to this: pulau,\n",
      "Nearest to this: another,\n",
      "Nearest to b: d,\n",
      "Nearest to b: ammonius,\n",
      "Nearest to b: sketch,\n",
      "Nearest to b: n,\n",
      "Nearest to b: canons,\n",
      "Nearest to b: six,\n",
      "Nearest to b: pulau,\n",
      "Nearest to b: mca,\n",
      "Nearest to by: was,\n",
      "Nearest to by: from,\n",
      "Nearest to by: coke,\n",
      "Nearest to by: six,\n",
      "Nearest to by: as,\n",
      "Nearest to by: in,\n",
      "Nearest to by: ursus,\n",
      "Nearest to by: through,\n",
      "Nearest to some: many,\n",
      "Nearest to some: these,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: the,\n",
      "Nearest to some: different,\n",
      "Nearest to some: sagan,\n",
      "Nearest to some: their,\n",
      "Nearest to some: several,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: michelob,\n",
      "Nearest to their: his,\n",
      "Nearest to their: its,\n",
      "Nearest to their: the,\n",
      "Nearest to their: her,\n",
      "Nearest to their: some,\n",
      "Nearest to their: fossil,\n",
      "Nearest to their: them,\n",
      "Nearest to their: vdc,\n",
      "Nearest to three: five,\n",
      "Nearest to three: four,\n",
      "Nearest to three: six,\n",
      "Nearest to three: two,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: seven,\n",
      "Nearest to three: circ,\n",
      "Nearest to three: ursus,\n",
      "Nearest to of: and,\n",
      "Nearest to of: albury,\n",
      "Nearest to of: in,\n",
      "Nearest to of: vdc,\n",
      "Nearest to of: nine,\n",
      "Nearest to of: for,\n",
      "Nearest to of: agouti,\n",
      "Nearest to of: following,\n",
      "Nearest to that: which,\n",
      "Nearest to that: this,\n",
      "Nearest to that: generally,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: where,\n",
      "Nearest to that: however,\n",
      "Nearest to that: michelob,\n",
      "Nearest to that: mound,\n",
      "average loss at step  62000 :  5.028953983664513\n",
      "average loss at step  64000 :  4.856190376579762\n",
      "average loss at step  66000 :  4.6120714054107665\n",
      "average loss at step  68000 :  4.9766334940195085\n",
      "average loss at step  70000 :  4.911192226290702\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: two,\n",
      "Nearest to into: from,\n",
      "Nearest to into: with,\n",
      "Nearest to into: under,\n",
      "Nearest to into: jeremiah,\n",
      "Nearest to into: on,\n",
      "Nearest to into: masculine,\n",
      "Nearest to into: against,\n",
      "Nearest to into: galaxies,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: pulau,\n",
      "Nearest to called: selig,\n",
      "Nearest to called: ursus,\n",
      "Nearest to called: UNK,\n",
      "Nearest to called: varphi,\n",
      "Nearest to called: while,\n",
      "Nearest to called: bennett,\n",
      "Nearest to than: or,\n",
      "Nearest to than: much,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: episkopos,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: sod,\n",
      "Nearest to than: believes,\n",
      "Nearest to than: env,\n",
      "Nearest to use: callithrix,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: industrialization,\n",
      "Nearest to use: marek,\n",
      "Nearest to use: pulau,\n",
      "Nearest to use: circ,\n",
      "Nearest to use: story,\n",
      "Nearest to no: oxidized,\n",
      "Nearest to no: there,\n",
      "Nearest to no: mcduck,\n",
      "Nearest to no: a,\n",
      "Nearest to no: airshow,\n",
      "Nearest to no: coalition,\n",
      "Nearest to no: aluminum,\n",
      "Nearest to no: drawn,\n",
      "Nearest to from: into,\n",
      "Nearest to from: after,\n",
      "Nearest to from: during,\n",
      "Nearest to from: in,\n",
      "Nearest to from: by,\n",
      "Nearest to from: on,\n",
      "Nearest to from: thaler,\n",
      "Nearest to from: at,\n",
      "Nearest to this: which,\n",
      "Nearest to this: it,\n",
      "Nearest to this: the,\n",
      "Nearest to this: that,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: cem,\n",
      "Nearest to this: another,\n",
      "Nearest to this: pulau,\n",
      "Nearest to b: d,\n",
      "Nearest to b: UNK,\n",
      "Nearest to b: seven,\n",
      "Nearest to b: n,\n",
      "Nearest to b: ursus,\n",
      "Nearest to b: ammonius,\n",
      "Nearest to b: callithrix,\n",
      "Nearest to b: upanija,\n",
      "Nearest to by: was,\n",
      "Nearest to by: from,\n",
      "Nearest to by: coke,\n",
      "Nearest to by: be,\n",
      "Nearest to by: through,\n",
      "Nearest to by: agouti,\n",
      "Nearest to by: against,\n",
      "Nearest to by: diab,\n",
      "Nearest to some: many,\n",
      "Nearest to some: these,\n",
      "Nearest to some: several,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: different,\n",
      "Nearest to some: sagan,\n",
      "Nearest to some: their,\n",
      "Nearest to some: all,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: two,\n",
      "Nearest to their: its,\n",
      "Nearest to their: his,\n",
      "Nearest to their: the,\n",
      "Nearest to their: her,\n",
      "Nearest to their: microcebus,\n",
      "Nearest to their: some,\n",
      "Nearest to their: them,\n",
      "Nearest to their: vdc,\n",
      "Nearest to three: four,\n",
      "Nearest to three: five,\n",
      "Nearest to three: six,\n",
      "Nearest to three: two,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: seven,\n",
      "Nearest to three: nine,\n",
      "Nearest to three: circ,\n",
      "Nearest to of: vdc,\n",
      "Nearest to of: and,\n",
      "Nearest to of: for,\n",
      "Nearest to of: albury,\n",
      "Nearest to of: in,\n",
      "Nearest to of: microsite,\n",
      "Nearest to of: mitral,\n",
      "Nearest to of: microcebus,\n",
      "Nearest to that: which,\n",
      "Nearest to that: this,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: what,\n",
      "Nearest to that: generally,\n",
      "Nearest to that: however,\n",
      "Nearest to that: mound,\n",
      "Nearest to that: where,\n",
      "average loss at step  72000 :  4.762070494890213\n",
      "average loss at step  74000 :  4.797721750974655\n",
      "average loss at step  76000 :  4.730297711133957\n",
      "average loss at step  78000 :  4.786565069913864\n",
      "average loss at step  80000 :  4.799635379076004\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: ursus,\n",
      "Nearest to into: from,\n",
      "Nearest to into: with,\n",
      "Nearest to into: in,\n",
      "Nearest to into: under,\n",
      "Nearest to into: through,\n",
      "Nearest to into: against,\n",
      "Nearest to into: jeremiah,\n",
      "Nearest to into: by,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: pulau,\n",
      "Nearest to called: selig,\n",
      "Nearest to called: ursus,\n",
      "Nearest to called: varphi,\n",
      "Nearest to called: bennett,\n",
      "Nearest to called: UNK,\n",
      "Nearest to called: while,\n",
      "Nearest to than: or,\n",
      "Nearest to than: much,\n",
      "Nearest to than: and,\n",
      "Nearest to than: episkopos,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: adriatic,\n",
      "Nearest to than: sod,\n",
      "Nearest to use: callithrix,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: industrialization,\n",
      "Nearest to use: incompressible,\n",
      "Nearest to use: pulau,\n",
      "Nearest to use: marek,\n",
      "Nearest to use: akimbo,\n",
      "Nearest to no: there,\n",
      "Nearest to no: oxidized,\n",
      "Nearest to no: mcduck,\n",
      "Nearest to no: coalition,\n",
      "Nearest to no: airshow,\n",
      "Nearest to no: pulau,\n",
      "Nearest to no: aluminum,\n",
      "Nearest to no: little,\n",
      "Nearest to from: into,\n",
      "Nearest to from: in,\n",
      "Nearest to from: after,\n",
      "Nearest to from: during,\n",
      "Nearest to from: at,\n",
      "Nearest to from: on,\n",
      "Nearest to from: thaler,\n",
      "Nearest to from: of,\n",
      "Nearest to this: which,\n",
      "Nearest to this: it,\n",
      "Nearest to this: that,\n",
      "Nearest to this: another,\n",
      "Nearest to this: the,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: cem,\n",
      "Nearest to this: pulau,\n",
      "Nearest to b: d,\n",
      "Nearest to b: UNK,\n",
      "Nearest to b: n,\n",
      "Nearest to b: ursus,\n",
      "Nearest to b: upanija,\n",
      "Nearest to b: callithrix,\n",
      "Nearest to b: seven,\n",
      "Nearest to b: circ,\n",
      "Nearest to by: was,\n",
      "Nearest to by: through,\n",
      "Nearest to by: coke,\n",
      "Nearest to by: be,\n",
      "Nearest to by: in,\n",
      "Nearest to by: agouti,\n",
      "Nearest to by: against,\n",
      "Nearest to by: from,\n",
      "Nearest to some: many,\n",
      "Nearest to some: these,\n",
      "Nearest to some: several,\n",
      "Nearest to some: different,\n",
      "Nearest to some: all,\n",
      "Nearest to some: their,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: sagan,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: two,\n",
      "Nearest to their: its,\n",
      "Nearest to their: his,\n",
      "Nearest to their: the,\n",
      "Nearest to their: her,\n",
      "Nearest to their: microcebus,\n",
      "Nearest to their: some,\n",
      "Nearest to their: them,\n",
      "Nearest to their: these,\n",
      "Nearest to three: six,\n",
      "Nearest to three: four,\n",
      "Nearest to three: five,\n",
      "Nearest to three: two,\n",
      "Nearest to three: seven,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: one,\n",
      "Nearest to three: circ,\n",
      "Nearest to of: vdc,\n",
      "Nearest to of: albury,\n",
      "Nearest to of: in,\n",
      "Nearest to of: microsite,\n",
      "Nearest to of: agouti,\n",
      "Nearest to of: circ,\n",
      "Nearest to of: nine,\n",
      "Nearest to of: for,\n",
      "Nearest to that: which,\n",
      "Nearest to that: this,\n",
      "Nearest to that: however,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: what,\n",
      "Nearest to that: mound,\n",
      "Nearest to that: michelob,\n",
      "Nearest to that: where,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss at step  82000 :  4.7797620091438295\n",
      "average loss at step  84000 :  4.752748112916946\n",
      "average loss at step  86000 :  4.782512287139893\n",
      "average loss at step  88000 :  4.751528748512268\n",
      "average loss at step  90000 :  4.954184674978256\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: ursus,\n",
      "Nearest to into: from,\n",
      "Nearest to into: with,\n",
      "Nearest to into: under,\n",
      "Nearest to into: through,\n",
      "Nearest to into: in,\n",
      "Nearest to into: to,\n",
      "Nearest to into: against,\n",
      "Nearest to into: on,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: pulau,\n",
      "Nearest to called: selig,\n",
      "Nearest to called: ursus,\n",
      "Nearest to called: UNK,\n",
      "Nearest to called: cnd,\n",
      "Nearest to called: varphi,\n",
      "Nearest to called: bennett,\n",
      "Nearest to than: or,\n",
      "Nearest to than: much,\n",
      "Nearest to than: episkopos,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: and,\n",
      "Nearest to than: env,\n",
      "Nearest to than: sod,\n",
      "Nearest to use: callithrix,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: pulau,\n",
      "Nearest to use: incompressible,\n",
      "Nearest to use: industrialization,\n",
      "Nearest to use: circ,\n",
      "Nearest to use: marek,\n",
      "Nearest to no: there,\n",
      "Nearest to no: oxidized,\n",
      "Nearest to no: little,\n",
      "Nearest to no: clerihew,\n",
      "Nearest to no: coalition,\n",
      "Nearest to no: airshow,\n",
      "Nearest to no: pulau,\n",
      "Nearest to no: a,\n",
      "Nearest to from: into,\n",
      "Nearest to from: after,\n",
      "Nearest to from: during,\n",
      "Nearest to from: in,\n",
      "Nearest to from: thaler,\n",
      "Nearest to from: at,\n",
      "Nearest to from: agouti,\n",
      "Nearest to from: six,\n",
      "Nearest to this: which,\n",
      "Nearest to this: it,\n",
      "Nearest to this: the,\n",
      "Nearest to this: that,\n",
      "Nearest to this: another,\n",
      "Nearest to this: cem,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: any,\n",
      "Nearest to b: d,\n",
      "Nearest to b: n,\n",
      "Nearest to b: UNK,\n",
      "Nearest to b: mca,\n",
      "Nearest to b: seven,\n",
      "Nearest to b: ursus,\n",
      "Nearest to b: latina,\n",
      "Nearest to b: six,\n",
      "Nearest to by: was,\n",
      "Nearest to by: through,\n",
      "Nearest to by: coke,\n",
      "Nearest to by: as,\n",
      "Nearest to by: from,\n",
      "Nearest to by: be,\n",
      "Nearest to by: in,\n",
      "Nearest to by: during,\n",
      "Nearest to some: many,\n",
      "Nearest to some: these,\n",
      "Nearest to some: several,\n",
      "Nearest to some: the,\n",
      "Nearest to some: different,\n",
      "Nearest to some: their,\n",
      "Nearest to some: beverley,\n",
      "Nearest to some: all,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: michelob,\n",
      "Nearest to their: its,\n",
      "Nearest to their: his,\n",
      "Nearest to their: the,\n",
      "Nearest to their: her,\n",
      "Nearest to their: some,\n",
      "Nearest to their: them,\n",
      "Nearest to their: microcebus,\n",
      "Nearest to their: these,\n",
      "Nearest to three: four,\n",
      "Nearest to three: five,\n",
      "Nearest to three: two,\n",
      "Nearest to three: seven,\n",
      "Nearest to three: six,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: one,\n",
      "Nearest to three: circ,\n",
      "Nearest to of: albury,\n",
      "Nearest to of: vdc,\n",
      "Nearest to of: microsite,\n",
      "Nearest to of: agouti,\n",
      "Nearest to of: microcebus,\n",
      "Nearest to of: in,\n",
      "Nearest to of: and,\n",
      "Nearest to of: michelob,\n",
      "Nearest to that: which,\n",
      "Nearest to that: this,\n",
      "Nearest to that: however,\n",
      "Nearest to that: what,\n",
      "Nearest to that: where,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: but,\n",
      "Nearest to that: generally,\n",
      "average loss at step  92000 :  4.672212540626526\n",
      "average loss at step  94000 :  4.734433172345161\n",
      "average loss at step  96000 :  4.694302290320397\n",
      "average loss at step  98000 :  4.59934612596035\n",
      "average loss at step  100000 :  4.692599358916283\n",
      "Nearest to zero: eight,\n",
      "Nearest to zero: five,\n",
      "Nearest to zero: four,\n",
      "Nearest to zero: nine,\n",
      "Nearest to zero: seven,\n",
      "Nearest to zero: six,\n",
      "Nearest to zero: three,\n",
      "Nearest to zero: ursus,\n",
      "Nearest to into: from,\n",
      "Nearest to into: through,\n",
      "Nearest to into: with,\n",
      "Nearest to into: under,\n",
      "Nearest to into: on,\n",
      "Nearest to into: around,\n",
      "Nearest to into: against,\n",
      "Nearest to into: immersed,\n",
      "Nearest to called: khoisan,\n",
      "Nearest to called: selig,\n",
      "Nearest to called: pulau,\n",
      "Nearest to called: and,\n",
      "Nearest to called: ursus,\n",
      "Nearest to called: UNK,\n",
      "Nearest to called: cnd,\n",
      "Nearest to called: varphi,\n",
      "Nearest to than: or,\n",
      "Nearest to than: much,\n",
      "Nearest to than: episkopos,\n",
      "Nearest to than: wear,\n",
      "Nearest to than: occupation,\n",
      "Nearest to than: env,\n",
      "Nearest to than: adriatic,\n",
      "Nearest to than: mid,\n",
      "Nearest to use: callithrix,\n",
      "Nearest to use: inherent,\n",
      "Nearest to use: initiation,\n",
      "Nearest to use: stenella,\n",
      "Nearest to use: pulau,\n",
      "Nearest to use: incompressible,\n",
      "Nearest to use: marek,\n",
      "Nearest to use: industrialization,\n",
      "Nearest to no: oxidized,\n",
      "Nearest to no: clerihew,\n",
      "Nearest to no: little,\n",
      "Nearest to no: coalition,\n",
      "Nearest to no: there,\n",
      "Nearest to no: mcduck,\n",
      "Nearest to no: pulau,\n",
      "Nearest to no: airshow,\n",
      "Nearest to from: into,\n",
      "Nearest to from: in,\n",
      "Nearest to from: during,\n",
      "Nearest to from: after,\n",
      "Nearest to from: agouti,\n",
      "Nearest to from: at,\n",
      "Nearest to from: thaler,\n",
      "Nearest to from: eight,\n",
      "Nearest to this: which,\n",
      "Nearest to this: it,\n",
      "Nearest to this: the,\n",
      "Nearest to this: another,\n",
      "Nearest to this: that,\n",
      "Nearest to this: circ,\n",
      "Nearest to this: cem,\n",
      "Nearest to this: some,\n",
      "Nearest to b: d,\n",
      "Nearest to b: n,\n",
      "Nearest to b: UNK,\n",
      "Nearest to b: ursus,\n",
      "Nearest to b: ammonius,\n",
      "Nearest to b: pulau,\n",
      "Nearest to b: canons,\n",
      "Nearest to b: circ,\n",
      "Nearest to by: through,\n",
      "Nearest to by: was,\n",
      "Nearest to by: as,\n",
      "Nearest to by: coke,\n",
      "Nearest to by: be,\n",
      "Nearest to by: agouti,\n",
      "Nearest to by: vdc,\n",
      "Nearest to by: from,\n",
      "Nearest to some: many,\n",
      "Nearest to some: these,\n",
      "Nearest to some: several,\n",
      "Nearest to some: the,\n",
      "Nearest to some: all,\n",
      "Nearest to some: their,\n",
      "Nearest to some: different,\n",
      "Nearest to some: beverley,\n",
      "Nearest to eight: seven,\n",
      "Nearest to eight: six,\n",
      "Nearest to eight: nine,\n",
      "Nearest to eight: five,\n",
      "Nearest to eight: four,\n",
      "Nearest to eight: three,\n",
      "Nearest to eight: zero,\n",
      "Nearest to eight: michelob,\n",
      "Nearest to their: its,\n",
      "Nearest to their: his,\n",
      "Nearest to their: the,\n",
      "Nearest to their: her,\n",
      "Nearest to their: some,\n",
      "Nearest to their: these,\n",
      "Nearest to their: them,\n",
      "Nearest to their: microcebus,\n",
      "Nearest to three: five,\n",
      "Nearest to three: four,\n",
      "Nearest to three: six,\n",
      "Nearest to three: seven,\n",
      "Nearest to three: eight,\n",
      "Nearest to three: two,\n",
      "Nearest to three: nine,\n",
      "Nearest to three: circ,\n",
      "Nearest to of: vdc,\n",
      "Nearest to of: in,\n",
      "Nearest to of: and,\n",
      "Nearest to of: including,\n",
      "Nearest to of: albury,\n",
      "Nearest to of: agouti,\n",
      "Nearest to of: michelob,\n",
      "Nearest to of: microsite,\n",
      "Nearest to that: which,\n",
      "Nearest to that: however,\n",
      "Nearest to that: what,\n",
      "Nearest to that: this,\n",
      "Nearest to that: circ,\n",
      "Nearest to that: but,\n",
      "Nearest to that: where,\n",
      "Nearest to that: mound,\n"
     ]
    }
   ],
   "source": [
    "num_steps = 100001\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    init.run() # Initialize variables, e.g. embedding vectors\n",
    "    print 'graph variables initialized'\n",
    "    \n",
    "    average_loss = 0\n",
    "    for step in xrange(num_steps):\n",
    "        batch_inputs, batch_labels = generate_batch(data, batch_size, num_skips, skip_window)\n",
    "        feed_dict = { train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "        _, loss_val = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        average_loss += loss_val\n",
    "        \n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= 2000\n",
    "\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print 'average loss at step ', step, ': ', average_loss\n",
    "            average_loss = 0\n",
    "        \n",
    "        if step % 10000 == 0:\n",
    "            sim = similarity.eval()\n",
    "            for i in xrange(valid_size):\n",
    "                valid_word = reverse_dictionary[valid_examples[i]]\n",
    "                top_k = 8  # number of nearest neighbors\n",
    "                nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                log_str = 'Nearest to %s:' % valid_word\n",
    "                for k in xrange(top_k):\n",
    "                    close_word = reverse_dictionary[nearest[k]]\n",
    "                    print '%s %s,' % (log_str, close_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "I can visualize it with PCA but in general PCA doesn't perform well on these non-linear features. t-SNE is the typical go-to choice for machine learning.\n",
    "\n",
    "![tsne](./assets/07_tsne.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
